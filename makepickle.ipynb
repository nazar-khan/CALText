{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"makepickle.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqy+Kes4uZ/kDjgqgGgh0G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"IWFJsac5epWT"},"source":["import os\n","import pandas as pd\n","import pickle as pkl\n","import sys\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2\n","\n","##Only include while running on colab\n","#from google.colab import drive\n","#drive.mount(\"/gdrive\", force_remount=True)\n","\n","#Directory path to save pickle files.\n","outFile='/gdrive/My Drive/URDU_V2_Exp/wap_exp/data_inv/train_images_inv.pkl'\n","outFile2='/gdrive/My Drive/URDU_V2_Exp/wap_exp/data_inv/train_labels_inv.pkl'\n","oupFp_feature=open(outFile,'wb')\n","oupFp_feature2=open(outFile2,'wb')\n","\n","#This noise function is used to add noise in images.\n","def add_salt_pepper_noise(X_imgs):\n","    # Need to produce a copy as to not modify the original image\n","    X_imgs_copy = X_imgs.copy()\n","    \n","    row, col= X_imgs_copy.shape\n","    salt_vs_pepper = 0.2\n","    amount = 0.04\n","    num_salt = np.ceil(amount * X_imgs_copy.size * salt_vs_pepper)\n","    num_pepper = np.ceil(amount * X_imgs_copy.size * (1.0 - salt_vs_pepper))\n","    \n","   \n","    # Add Salt noise\n","    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in X_imgs.shape]\n","    X_imgs[coords[0], coords[1]] = 1\n","\n","    # Add Pepper noise\n","    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in X_imgs.shape]\n","    X_imgs[coords[0], coords[1]] = 0\n","    return X_imgs\n","  \n","#Automatically generate dictionary array by reading training labels.\n","def load_dict(labelfile):\n","    count=0\n","    df=pd.read_excel(labelfile)\n","    lexicon={}\n","    lex_ind=[]\n","    j=1\n","    key=1\n","    for i in df.index: \n","      caption=df['Revised'][i]\n","      count=count+1\n","      slen=len(caption)\n","      i=0\n","      while(i<slen):\n","        ss=caption[i]\n","        \n","        if(ss=='ة' or ss=='ۃ'):\n","          ss='ت'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ہ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","        if(ss=='ي'):\n","          ss='ے'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ی'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","        if(ss=='ؤ' or ss=='ﺅ'):\n","          ss='ٔ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","           \n","            j=j+1\n","            key=key+1\n","\n","          ss='و'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","        if(ss=='ئ'):\n","          ss='ٔ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ی'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","        if(ss=='ۂ'):\n","          ss='ٔ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ہ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","        if(ss=='ۓ'):\n","          ss='ٔ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ے'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","        if(ss=='أ'):\n","          ss='ٔ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ا'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","        if(ss=='ﷲ'):\n","          ss='ا'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","          ss='ل'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1 \n","          ss='ل'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1 \n","          ss='ہ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1 \n","\n","        if(ss=='ٔ' or ss=='ٔ'):\n","          ss='ٔ'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","\n","        if(ss=='\\u200f' or ss=='\\u200c' or ss=='\\ufeff' or ss==' ' or ss=='\\n'):\n","          ss=' '  \n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","             \n","        if(ss=='-' or ss=='۔'):\n","          ss='۔'\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1  \n","        else:\n","          if ss not in lexicon:\n","            lexicon[ss]=int(key)\n","            lex_ind.append(j)\n","            j=j+1\n","            key=key+1\n","       \n","        i=i+1\n","  \n","    return lexicon,lex_ind\n","\n","#This function reads labels and corresponding images from given paths of data. Urdu Llabels are converted to numbers using dictionary. \n","#Images are resized and some noise is also added which helps to reduce overfitting during the training process.\n","def  load_labels_from_folder(imgfolder,labelfile,dictionary):  \n","  \n","    labels=[]\n","    images={}\n","    count=0\n","    scpFile=open(labelfile)\n","    df=pd.read_excel(labelfile)\n","    split_ch='-'\n","    \n","    i=0\n","    for i in df.index:\n","      line=df['Num'][i]#Num\n","      caption=df['Revised'][i]# Caption\n","      slen=len(caption)\n","      j=0\n","\n","      image_file = imgfolder + line.strip() + '.png'\n","      img = cv2.imread(image_file,-1)\n","      \n","      if img is None:\n","        print(image_file)\n","      else:\n","        if len(img.shape)>2:\n","          img= cv2.cvtColor(img.astype('float32'), cv2.COLOR_BGR2GRAY)\n","        height=img.shape[0]\n","        width=img.shape[1]\n","        #print(width)\n","        if(width<300):\n","          result = np.ones([img.shape[0], img.shape[1]*2])*255\n","          result[0:img.shape[0],img.shape[1]:img.shape[1]*2]=img\n","          img=cv2.resize(result, dsize=(800,100), interpolation = cv2.INTER_AREA)      \n","        else:\n","          img=cv2.resize(img, dsize=(800,100), interpolation = cv2.INTER_AREA)\n","          \n","        img=add_salt_pepper_noise(img)\n","        images[count]=img\n","        count=count+1\n","        \n","\n","        w_list=[]\n","      \n","        w=0\n","        while(w < slen):\n","          ss=caption[w]\n","          if(ss=='ي'):\n","            ss='ے'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","            ss='ی'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","          elif(ss=='ة'):\n","            ss='ت'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","            ss='ہ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","          elif(ss=='ؤ' or ss=='ﺅ'):\n","            ss='ٔ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","            ss='و'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","          elif(ss=='ئ'):\n","            ss='ٔ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","            ss='ی'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","          elif(ss=='ۂ'):\n","            ss='ٔ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","            ss='ہ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","          elif(ss=='ۓ'):\n","            ss='ٔ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","            ss='ے'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","          elif(ss=='أ'):\n","            ss='ٔ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","            ss='ا'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","          elif(ss=='ﷲ'):\n","            ss='ا'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","            ss='ل'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss]) \n","            ss='ل'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss]) \n","            ss='ہ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss]) \n","\n","          elif(ss=='ٔ' or ss=='ٔ'):\n","            ss='ٔ'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","          elif(ss==' '):\n","            ss=' '  \n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","\n","          elif(ss=='-' or ss=='۔'):\n","            ss='۔'\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","          else:\n","            if ss in dictionary:\n","              w_list.append(dictionary[ss])\n","          w=w+1\n","\n","        \n","        xx=w_list[::-1]\n","        xx.append(0)\n","        labels.append(xx)\n","        i=i+1\n","\n","      if (np.mod(count, 200) == 0):\n","        print(count)  \n","    return images, labels  \n","\n","      \n","worddicts,wordindexes = load_dict('/gdrive/My Drive/URDU_V2_Exp/V2_data/train_labels_combined.xlsx') \n","print(worddicts)#dictionary\n","images,labels=load_labels_from_folder('/gdrive/My Drive/URDU FINAL/variable images experiment/train_lines/','/gdrive/My Drive/URDU_V2_Exp/V2_data/train_labels_combined.xlsx',worddicts)\n","\n","\n","pkl.dump(images,oupFp_feature)\n","pkl.dump(labels,oupFp_feature2)\n","print ('save file done')\n","oupFp_feature.close()\n","oupFp_feature2.close()"],"execution_count":null,"outputs":[]}]}