{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CALText.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLEMw3pVUQPSreXc5CK79H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9YNC5XhqBoi","executionInfo":{"status":"ok","timestamp":1635408061768,"user_tz":-300,"elapsed":509,"user":{"displayName":"TAYABA ANJUM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10851116605193077567"}},"outputId":"c4ce75d8-8e47-49e1-8080-b8a58754210e"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","metadata":{"id":"ssoJJPttiPyD"},"source":["import tensorflow as tf\n","from tensorflow.contrib.layers import batch_norm\n","from tensorflow.contrib.framework import arg_scope\n","from matplotlib import pyplot as plt\n","from tensorflow.keras import regularizers\n","import numpy as np\n","import random\n","import sys\n","import copy\n","import re\n","import os\n","import time\n","import math\n","import pandas as pd\n","import pickle as pkl\n","import gzip\n","import cv2\n","import matplotlib.cm as cm\n","from skimage.transform import rescale, resize\n","rng = np.random.RandomState(int(time.time()))\n","\n","\n","NUM_CLASSES=130\n","BATCHSIZE=4\n","MODE='test'\n","\n","##Only include while running on colab\n","#from google.colab import drive\n","#drive.mount('/gdrive', force_remount=True)\n","\n","'''\n","Following three functions:\n","norm_weight(),\n","conv_norm_weight(),\n","ortho_weight()\n","are initialization methods for weights.\n","'''\n","def norm_weight(fan_in, fan_out):\n","\tW_bound = np.sqrt(6.0 / (fan_in + fan_out))\n","\treturn np.asarray(rng.uniform(low=-W_bound, high=W_bound, size=(fan_in, fan_out)), dtype=np.float32)\n"," \n","def conv_norm_weight(nin, nout, kernel_size):\n","    filter_shape = (kernel_size[0], kernel_size[1], nin, nout)\n","    fan_in = kernel_size[0] * kernel_size[1] * nin\n","    fan_out = kernel_size[0] * kernel_size[1] * nout\n","    W_bound = np.sqrt(6. / (fan_in + fan_out))\n","    W = np.asarray(rng.uniform(low=-W_bound, high=W_bound, size=filter_shape), dtype=np.float32)\n","    return W.astype('float32')\n","\n","def ortho_weight(ndim):\n","\tW = np.random.randn(ndim, ndim)\n","\tu, s, v = np.linalg.svd(W)\n","\treturn u.astype('float32')\n","\n","'''\n","Watch_train class implements DenseNet encoder \n","using bottleneck layers. Encoder contains three dense blocks. \n","'''\n","class Watcher_train():\n","\tdef __init__(self, blocks,       # number of dense blocks\n","\t\t\t\tlevel,                     # number of levels in each blocks\n","\t\t\t\tgrowth_rate,               # growth rate in DenseNet paper: k\n","\t\t\t\ttraining,\n","\t\t\t\tdropout_rate=0.2,          # keep-rate of dropout layer\n","\t\t\t\tdense_channels=0,          # filter numbers of transition layer's input\n","\t\t\t\ttransition=0.5,            # rate of comprssion\n","\t\t\t\tinput_conv_filters=48,     # filter numbers of conv2d before dense blocks\n","\t\t\t\tinput_conv_stride=2,       # stride of conv2d before dense blocks\n","\t\t\t\tinput_conv_kernel=[7,7]):  # kernel size of conv2d before dense blocks\n","\t\tself.blocks = blocks\n","\t\tself.growth_rate = growth_rate\n","\t\tself.training = training\n","\t\tself.dense_channels = dense_channels\n","\t\tself.level = level\n","\t\tself.dropout_rate = dropout_rate\n","\t\tself.transition = transition\n","\t\tself.input_conv_kernel = input_conv_kernel\n","\t\tself.input_conv_stride = input_conv_stride\n","\t\tself.input_conv_filters = input_conv_filters\n","\n","\tdef bound(self, nin, nout, kernel):\n","\t\tfin = nin * kernel[0] * kernel[1]\n","\t\tfout = nout * kernel[0] * kernel[1]\n","\t\treturn np.sqrt(6. / (fin + fout))\n","    \n","\tdef dense_net(self, input_x, mask_x):\n","\n","\t\t#### before flowing into dense blocks ####\n","\t\tinput_x=tf.expand_dims(input=input_x, axis=3)\n","\t\tx = input_x\n","\t\tlimit = self.bound(1, self.input_conv_filters, self.input_conv_kernel)\n","\t\tx = tf.layers.conv2d(x, filters=self.input_conv_filters, strides=self.input_conv_stride,\n","\t\t\tkernel_size=self.input_conv_kernel, padding='SAME', data_format='channels_last', use_bias=False, kernel_initializer=tf.random_uniform_initializer(-limit, limit, dtype=tf.float32))\n","\t\tmask_x = mask_x[:, 0::2, 0::2]\n","\t\tx = tf.layers.batch_normalization(x, training=self.training, momentum=0.9, scale=True, gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(self.input_conv_filters),\n","\t\t\t\t1.0/math.sqrt(self.input_conv_filters), dtype=tf.float32), epsilon=0.0001)\n","\t\tx = tf.nn.relu(x)\n","\t\tx = tf.layers.max_pooling2d(inputs=x, pool_size=[2,2], strides=2, padding='SAME')\n","\t\t\n","\t\tinput_pre = x\n","\t\tmask_x = mask_x[:, 0::2, 0::2]\n","\t\tself.dense_channels += self.input_conv_filters\n","\t\tdense_out = x\n","\n","\t\t#### flowing into dense blocks and transition_layer ####\n","\t\tfor i in range(self.blocks):\n","\t\t\tfor j in range(self.level):\n","\n","\t\t\t\t#### [1, 1] convolution part for bottleneck ####\n","\t\t\t\tlimit = self.bound(self.dense_channels, 4 * self.growth_rate, [1,1])\n","\t\t\t\tx = tf.layers.conv2d(x, filters=4 * self.growth_rate, kernel_size=[1,1],\n","\t\t\t\t\tstrides=1, padding='VALID', data_format='channels_last', use_bias=False, kernel_initializer=tf.random_uniform_initializer(-limit, limit, dtype=tf.float32))\n","\t\t\t\tx = tf.layers.batch_normalization(inputs=x,  training=self.training, momentum=0.9, scale=True, gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(4 * self.growth_rate),\n","\t\t\t\t\t1.0/math.sqrt(4 * self.growth_rate), dtype=tf.float32), epsilon=0.0001)\n","\t\t\t\tx = tf.nn.relu(x)\n","\t\t\t\tx = tf.layers.dropout(inputs=x, rate=self.dropout_rate, training=self.training)\n","\n","\t\t\t\t#### [3, 3] convolution part for regular convolve operation\n","\t\t\t\tlimit = self.bound(4 * self.growth_rate, self.growth_rate, [3,3])\n","\t\t\t\tx = tf.layers.conv2d(x, filters=self.growth_rate, kernel_size=[3,3],\n","\t\t\t\t\tstrides=1, padding='SAME', data_format='channels_last', use_bias=False, kernel_initializer=tf.random_uniform_initializer(-limit, limit, dtype=tf.float32))\n","\t\t\t\tx = tf.layers.batch_normalization(inputs=x, training=self.training, momentum=0.9, scale=True, gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(self.growth_rate),\n","\t\t\t\t\t1.0/math.sqrt(self.growth_rate), dtype=tf.float32), epsilon=0.0001)\n","\t\t\t\tx = tf.nn.relu(x)\n","\n","\t\t\t\tx = tf.layers.dropout(inputs=x, rate=self.dropout_rate, training=self.training)\n","\n","\t\t\t\tdense_out = tf.concat([dense_out, x], axis=3)\n","\t\t\t\tx = dense_out\n","\t\t\t\t#### calculate the filter number of dense block's output ####\n","\t\t\t\tself.dense_channels += self.growth_rate\n","\n","\t\t\tif i < self.blocks - 1:\n","\t\t\t\tcompressed_channels = int(self.dense_channels * self.transition)\n","\n","\t\t\t\t#### new dense channels for new dense block ####\n","\t\t\t\tself.dense_channels = compressed_channels\n","\t\t\t\tlimit = self.bound(self.dense_channels, compressed_channels, [1,1])\n","\t\t\t\tx = tf.layers.conv2d(x, filters=compressed_channels, kernel_size=[1,1],\n","\t\t\t\t\tstrides=1, padding='VALID', data_format='channels_last', use_bias=False, kernel_initializer=tf.random_uniform_initializer(-limit, limit, dtype=tf.float32))\n","\t\t\t\tx = tf.layers.batch_normalization(x, training=self.training, momentum=0.9, scale=True, gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(self.dense_channels),\n","\t\t\t\t\t\t1.0/math.sqrt(self.dense_channels), dtype=tf.float32), epsilon=0.0001)\n","\t\t\t\tx = tf.nn.relu(x)\n","\t\t\t\tx = tf.layers.dropout(inputs=x, rate=self.dropout_rate, training=self.training)\n","    \n","\t\t\t\tx = tf.layers.average_pooling2d(inputs=x, pool_size=[2,2], strides=2, padding='SAME')\n","\t\t\t\tdense_out = x\n","\t\t\t\tmask_x = mask_x[:, 0::2, 0::2]\n","\n","\t\treturn dense_out, mask_x\n","\n","'''\n","Attender class implements contextual attention mechanism. \n","'''\n","class Attender():\n","\tdef __init__(self, channels,                          # output of Watcher | [batch, h, w, channels]\n","\t\t\t\tdim_decoder, dim_attend):                       # decoder hidden state:$h_{t-1}$ | [batch, dec_dim]\n","\n","\t\tself.channels = channels\n","\n","\t\tself.coverage_kernel = [11,11]                      # kernel size of $Q$\n","\t\tself.coverage_filters = dim_attend                  # filter numbers of $Q$ | 512\n","\n","\t\tself.dim_decoder = dim_decoder                      # 256\n","\t\tself.dim_attend = dim_attend                        # unified dim of three parts calculating $e_ti$ i.e.\n","\t\t                                                    # $Q*beta_t$, $U_a * a_i$, $W_a x h_{t-1}$ | 512\n","\t\tself.U_f = tf.Variable(norm_weight(self.coverage_filters, self.dim_attend), name='U_f') # $U_f x f_i$ | [cov_filters, dim_attend]\n","\t\tself.U_f_b = tf.Variable(np.zeros((self.dim_attend,)).astype('float32'), name='U_f_b')  # $U_f x f_i + U_f_b$ | [dim_attend, ]\n","\n","\t\tself.U_a = tf.Variable(norm_weight(self.channels,self.dim_attend), name='U_a')         # $U_a x a_i$ | [annotatin_channels, dim_attend]\n","\t\tself.U_a_b = tf.Variable(np.zeros((self.dim_attend,)).astype('float32'), name='U_a_b') # $U_a x a_i + U_a_b$ | [dim_attend, ]\n","\n","\t\tself.W_a = tf.Variable(norm_weight(self.dim_decoder,self.dim_attend), name='W_a')      # $W_a x h_{t_1}$ | [dec_dim, dim_attend]\n","\t\tself.W_a_b = tf.Variable(np.zeros((self.dim_attend,)).astype('float32'), name='W_a_b') # $W_a x h_{t-1} + W_a_b$ | [dim_attend, ]\n","\n","\t\tself.V_a = tf.Variable(norm_weight(self.dim_attend, 1), name='V_a')                    # $V_a x tanh(A + B + C)$ | [dim_attend, 1]\n","\t\tself.V_a_b = tf.Variable(np.zeros((1,)).astype('float32'), name='V_a_b')               # $V_a x tanh(A + B + C) + V_a_b$ | [1, ]\n","\n","\t\tself.alpha_past_filter = tf.Variable(conv_norm_weight(1, self.dim_attend, self.coverage_kernel), name='alpha_past_filter')\n","\n","\n","\tdef get_context(self, annotation4ctx, h_t_1, alpha_past4ctx, a_mask):\n","\n","\t\t#### calculate $U_f x f_i$ ####\n","\t\talpha_past_4d = alpha_past4ctx[:, :, :, None]\n","\n","\t\tFt = tf.nn.conv2d(alpha_past_4d, filter=self.alpha_past_filter, strides=[1, 1, 1, 1], padding='SAME')\n","\t\tcoverage_vector = tf.tensordot(Ft, self.U_f, axes=1) \t+ self.U_f_b    # [batch, h, w, dim_attend]\n","\n","\t\t#### calculate $U_a x a_i$ ####\n","\t\twatch_vector = tf.tensordot(annotation4ctx, self.U_a, axes=1) + self.U_a_b   # [batch, h, w, dim_attend]\n","\n","\t\t#### calculate $W_a x h_{t - 1}$ ####\n","\t\tspeller_vector = tf.tensordot(h_t_1, self.W_a, axes=1) + self.W_a_b   # [batch, dim_attend]\n","\t\tspeller_vector = speller_vector[:, None, None, :]    # [batch, None, None, dim_attend]\n","\n","\t\ttanh_vector = tf.tanh(coverage_vector + watch_vector + speller_vector)    # [batch, h, w, dim_attend]\n","\t\te_ti = tf.tensordot(tanh_vector, self.V_a, axes=1) + self.V_a_b  # [batch, h, w, 1]\n","\t\talpha = tf.exp(e_ti)\n","\t\talpha = tf.squeeze(alpha, axis=3)\n","\n","\t\tif a_mask is not None:\n","\t\t\talpha = alpha * a_mask\n","\n","\t\talpha = alpha / tf.reduce_sum(alpha, axis=[1, 2], keepdims=True)    # normlized weights | [batch, h, w]\n","\t\talpha_past4ctx += alpha    # accumalated weights matrix | [batch, h, w]\n","\t\tcontext = tf.reduce_sum(annotation4ctx * alpha[:, :, :, None], axis=[1, 2])   # context vector | [batch, feature_channels]\n","\t\treturn context, alpha, alpha_past4ctx\n","\n","'''\n","Parser class implements 2 layerd Decoder (GRU) which decodes an input image \n","and outputs a seuence of characters using attention mechanism . \n","'''\n","class Parser():\n","\tdef __init__(self, hidden_dim, word_dim, attender, context_dim):\n","\n","\t\tself.attender = attender                                # inner-instance of Attender to provide context\n","\t\tself.context_dim = context_dim                          # context dime 684\n","\t\tself.hidden_dim = hidden_dim                            # dim of hidden state  256\n","\t\tself.word_dim = word_dim                                # dim of embedding word 256\n","\t\t\n","\t\t##GRU 1 weights initialization starts here\n","\t\tself.W_yz_yr = tf.Variable(np.concatenate(\n","\t\t\t[norm_weight(self.word_dim, self.hidden_dim), norm_weight(self.word_dim, self.hidden_dim)], axis=1), name='W_yz_yr') # [dim_word, 2 * dim_decoder]\n","\t\tself.b_yz_yr = tf.Variable(np.zeros((2 * self.hidden_dim, )).astype('float32'), name='b_yz_yr')\n","\n","\t\tself.U_hz_hr = tf.Variable(np.concatenate(\n","\t\t\t[ortho_weight(self.hidden_dim),ortho_weight(self.hidden_dim)], axis=1), name='U_hz_hr')                              # [dim_hidden, 2 * dim_hidden]\n","\n","\t\tself.W_yh = tf.Variable(norm_weight(self.word_dim,\n","\t\t\tself.hidden_dim), name='W_yh')\n","\t\tself.b_yh = tf.Variable(np.zeros((self.hidden_dim, )).astype('float32'), name='b_yh')                                    # [dim_decoder, ]\n","\n","\t\tself.U_rh = tf.Variable(ortho_weight(self.hidden_dim), name='U_rh')                                                      # [dim_hidden, dim_hidden]\n","\n","\t\t##GRU 2 weights initialization starts here\n","\t\tself.U_hz_hr_nl = tf.Variable(np.concatenate(\n","\t\t\t[ortho_weight(self.hidden_dim), ortho_weight(self.hidden_dim)], axis=1), name='U_hz_hr_nl')                          # [dim_hidden, 2 * dim_hidden] non_linear\n","\n","\t\tself.b_hz_hr_nl = tf.Variable(np.zeros((2 * self.hidden_dim, )).astype('float32'), name='b_hz_hr_nl')                    # [2 * dim_hidden, ]\n","\n","\t\tself.W_c_z_r = tf.Variable(norm_weight(self.context_dim,\n","\t\t\t2 * self.hidden_dim), name='W_c_z_r')\n","\n","\t\tself.U_rh_nl = tf.Variable(ortho_weight(self.hidden_dim), name='U_rh_nl')\n","\t\tself.b_rh_nl = tf.Variable(np.zeros((self.hidden_dim, )).astype('float32'), name='b_rh_nl')\n","\n","\t\tself.W_c_h_nl = tf.Variable(norm_weight(self.context_dim, self.hidden_dim), name='W_c_h_nl')\n","\n","\n","\n","\tdef get_ht_ctx(self, emb_y, target_hidden_state_0, annotations, a_m, y_m):\n","\n","\t\tres = tf.scan(self.one_time_step, elems=(emb_y, y_m),\n","\t\t\tinitializer=(target_hidden_state_0,\n","\t\t\t\ttf.zeros([tf.shape(annotations)[0], self.context_dim]),\n","\t\t\t\ttf.zeros([tf.shape(annotations)[0], tf.shape(annotations)[1], tf.shape(annotations)[2]]),\n","\t\t\t\ttf.zeros([tf.shape(annotations)[0], tf.shape(annotations)[1], tf.shape(annotations)[2]]),\n","\t\t\t\tannotations, a_m))\n","\n","\t\treturn res\n","\n","\n","\n","\n","\tdef one_time_step(self, tuple_h0_ctx_alpha_alpha_past_annotation, tuple_emb_mask):\n","\n","\t\ttarget_hidden_state_0 = tuple_h0_ctx_alpha_alpha_past_annotation[0]\n","\t\talpha_past_one        = tuple_h0_ctx_alpha_alpha_past_annotation[3]\n","\t\tannotation_one        = tuple_h0_ctx_alpha_alpha_past_annotation[4]\n","\t\ta_mask                = tuple_h0_ctx_alpha_alpha_past_annotation[5]\n","\n","\t\temb_y, y_mask = tuple_emb_mask\n","\n","\t\t#GRU 1 starts here\n","\t\temb_y_z_r_vector = tf.tensordot(emb_y, self.W_yz_yr, axes=1) + \\\n","\t\tself.b_yz_yr                                            # [batch, 2 * dim_decoder]\n","\t\thidden_z_r_vector = tf.tensordot(target_hidden_state_0,\n","\t\tself.U_hz_hr, axes=1)                                   # [batch, 2 * dim_decoder]\n","\t\tpre_z_r_vector = tf.sigmoid(emb_y_z_r_vector + \\\n","\t\thidden_z_r_vector)                                      # [batch, 2 * dim_decoder]\n","\n","\t\tr1 = pre_z_r_vector[:, :self.hidden_dim]                # [batch, dim_decoder]\n","\t\tz1 = pre_z_r_vector[:, self.hidden_dim:]                # [batch, dim_decoder]\n","\n","\t\temb_y_h_vector = tf.tensordot(emb_y, self.W_yh, axes=1) + \\\n","\t\tself.b_yh                                               # [batch, dim_decoder]\n","\t\thidden_r_h_vector = tf.tensordot(target_hidden_state_0,\n","\t\tself.U_rh, axes=1)                                      # [batch, dim_decoder]\n","\t\thidden_r_h_vector *= r1\n","\t\tpre_h_proposal = tf.tanh(hidden_r_h_vector + emb_y_h_vector)\n","\n","\t\tpre_h = z1 * target_hidden_state_0 + (1. - z1) * pre_h_proposal\n","\n","\t\tif y_mask is not None:\n","\t\t\tpre_h = y_mask[:, None] * pre_h + (1. - y_mask)[:, None] * target_hidden_state_0\n","\n","\t\tcontext, alpha, alpha_past_one = self.attender.get_context(annotation_one, pre_h, alpha_past_one, a_mask)  # [batch, dim_ctx]\n","\t\t\n","\t\t#GRU 2 starts here\n","\t\temb_y_z_r_nl_vector = tf.tensordot(pre_h, self.U_hz_hr_nl, axes=1) + self.b_hz_hr_nl\n","\t\tcontext_z_r_vector = tf.tensordot(context, self.W_c_z_r, axes=1)\n","\t\tz_r_vector = tf.sigmoid(emb_y_z_r_nl_vector + context_z_r_vector)\n","\n","\t\tr2 = z_r_vector[:, :self.hidden_dim]\n","\t\tz2 = z_r_vector[:, self.hidden_dim:]\n","\n","\t\temb_y_h_nl_vector = tf.tensordot(pre_h, self.U_rh_nl, axes=1) \n","\t\temb_y_h_nl_vector *= r2\n","\t\temb_y_h_nl_vector=emb_y_h_nl_vector+ self.b_rh_nl # bias added after point wise multiplication with r2\n","\t\tcontext_h_vector = tf.tensordot(context, self.W_c_h_nl, axes=1)\n","\t\th_proposal = tf.tanh(emb_y_h_nl_vector + context_h_vector)\n","\t\th = z2 * pre_h + (1. - z2) * h_proposal\n","\n","\t\tif y_mask is not None:\n","\t\t\th = y_mask[:, None] * h + (1. - y_mask)[:, None] * pre_h\n","\n","\t\treturn h, context, alpha, alpha_past_one, annotation_one, a_mask\n","\n","\n","'''\n","WAP class is the main class. This class uses below three classes:\n","1) Watch_train (Encoder)\n","2) Attender (Contextual attention mechnism)\n","3) Parser (2 layerd GRU Decoder)\n","WAP class implements two functions get_cost and get_sample, which are actually used for cost calculation and decoding.\n","'''\n","class WAP():\n","\tdef __init__(self, watcher, attender, parser, hidden_dim, word_dim, context_dim, target_dim, training):\n","\n","\t\t#self.batch_size = batch_size\n","\t\tself.hidden_dim = hidden_dim\n","\t\tself.word_dim = word_dim\n","\t\tself.context_dim = context_dim\n","\t\tself.target_dim = target_dim\n","\t\tself.embed_matrix = tf.Variable(norm_weight(self.target_dim, self.word_dim), name='embed')\n","\n","\t\tself.watcher = watcher\n","\t\tself.attender = attender\n","\t\tself.parser = parser\n","\t\tself.Wa2h = tf.Variable(norm_weight(self.context_dim, self.hidden_dim), name='Wa2h')\n","\t\tself.ba2h = tf.Variable(np.zeros((self.hidden_dim,)).astype('float32'), name='ba2h')\n","\t\tself.Wc = tf.Variable(norm_weight(self.context_dim, self.word_dim), name='Wc')\n","\t\tself.bc = tf.Variable(np.zeros((self.word_dim,)).astype('float32'), name='bc')\n","\t\tself.Wh = tf.Variable(norm_weight(self.hidden_dim, self.word_dim), name='Wh')\n","\t\tself.bh = tf.Variable(np.zeros((self.word_dim,)).astype('float32'), name='bh')\n","\t\tself.Wy = tf.Variable(norm_weight(self.word_dim, self.word_dim), name='Wy')\n","\t\tself.by = tf.Variable(np.zeros((self.word_dim,)).astype('float32'), name='by')\n","\t\tself.Wo = tf.Variable(norm_weight(self.word_dim//2, self.target_dim), name='Wo')\n","\t\tself.bo = tf.Variable(np.zeros((self.target_dim,)).astype('float32'), name='bo')\n","\t\tself.training = training\n","\n","\n","\tdef get_cost(self, cost_annotation, cost_y, a_m, y_m,alpha_reg):\n","\t\t\n","\t\t#### step: 1 prepration of embedding of labels sequences #### \n","\t\ttimesteps = tf.shape(cost_y)[0]\n","\t\tbatch_size = tf.shape(cost_y)[1]\n","\t\temb_y = tf.nn.embedding_lookup(self.embed_matrix, tf.reshape(cost_y, [-1]))\n","\t\temb_y = tf.reshape(emb_y, [timesteps, batch_size, self.word_dim])\n","\t\temb_pad = tf.fill((1, batch_size, self.word_dim), 0.0)\n","\t\temb_shift = tf.concat([emb_pad ,tf.strided_slice(emb_y, [0, 0, 0], [-1, batch_size, self.word_dim], [1, 1, 1])], axis=0)\n","\t\tnew_emb_y = emb_shift\n","\n","\t\t#### step: 2 calculation of h_0 #### \n","\t\tanno_mean = tf.reduce_sum(cost_annotation * a_m[:, :, :, None], axis=[1, 2]) / tf.reduce_sum(a_m, axis=[1, 2])[:, None]\n","\t\th_0 = tf.tensordot(anno_mean, self.Wa2h, axes=1) + self.ba2h  # [batch, hidden_dim]\n","\t\th_0 = tf.tanh(h_0)\n","\t\n","\t\t#### step: 3 calculation of h_t and c_t at all time steps #### \n","\t\tret = self.parser.get_ht_ctx(new_emb_y, h_0, cost_annotation, a_m, y_m)\n","\t\th_t = ret[0]                      # h_t of all timesteps [timesteps, batch, hidden_dim]\n","\t\tc_t = ret[1]                      # c_t of all timesteps [timesteps, batch, context_dim]\n","\t\talpha=ret[2]\t\t\t\t\t\t\t\t\t\t\t# alpha of all timesteps [timesteps, batch, h, w]\n","\n","\t\t#### step: 4 calculation of cost using h_t, c_t and y_t_1 ####\n","\t\ty_t_1 = new_emb_y                 # shifted y | [1:] = [:-1]\n","\t\tlogit_gru = tf.tensordot(h_t, self.Wh, axes=1) + self.bh\n","\t\tlogit_ctx = tf.tensordot(c_t, self.Wc, axes=1) + self.bc\n","\t\tlogit_pre = tf.tensordot(y_t_1, self.Wy, axes=1) + self.by\n","\t\tlogit = logit_pre + logit_ctx + logit_gru\n","\t\tshape = tf.shape(logit)\n","\t\tlogit = tf.reshape(logit, [shape[0], -1, shape[2]//2, 2])\n","\t\tlogit = tf.reduce_max(logit, axis=3)\n","\t\tlogit = tf.layers.dropout(inputs=logit, rate=0.2, training=self.training)\n","\t\tlogit = tf.tensordot(logit, self.Wo, axes=1) + self.bo\n","\t\tlogit_shape = tf.shape(logit)\n","\t\tlogit = tf.reshape(logit, [-1,logit_shape[2]])\n","\t\tcost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=tf.one_hot(tf.reshape(cost_y, [-1]),depth=self.target_dim))\n","\t\t\n","\t\t#### max pooling on vector with size equal to word_dim ####\n","\t\tcost = tf.multiply(cost, tf.reshape(y_m, [-1]))\n","\t\tcost = tf.reshape(cost, [shape[0], shape[1]])\n","\t\tcost = tf.reduce_sum(cost, axis=0)\n","\t\tcost = tf.reduce_mean(cost)\n","\t\n","\t\t#### alpha  L1 regularization ####\n","\t\talpha_sum=tf.reduce_mean(tf.reduce_sum(tf.reduce_sum(tf.abs(alpha), axis=[2, 3]),axis=0))\t\t\t\n","\t\tcost = tf.cond(alpha_reg > 0,  \tlambda: cost + (alpha_reg * alpha_sum), lambda: cost)\n","\n","\t\treturn cost\n","\n","\n","\t'''\n","\tThe get_word function is called from get_sample function. At first time calll, \n","\tbatch size is equal to 1, later it is called with batch size equal to live_k. \n","\t'''\n","\tdef get_word(self, sample_y, sample_h_pre, alpha_past_pre, sample_annotation):\n","\n","\t\temb = tf.cond(sample_y[0] < 0,\n","\t\t\tlambda: tf.fill((1, self.word_dim), 0.0),\n","\t\t\tlambda: tf.nn.embedding_lookup(self.embed_matrix, sample_y)\n","\t\t\t)\n","\n","\t\t#ret = self.parser.one_time_step((h_pre, None, None, alpha_past_pre, annotation, None), (emb, None))\n","\t\temb_y_z_r_vector = tf.tensordot(emb, self.parser.W_yz_yr, axes=1) + \\\n","\t\tself.parser.b_yz_yr                                            # [batch, 2 * dim_decoder]\n","\t\thidden_z_r_vector = tf.tensordot(sample_h_pre,\n","\t\tself.parser.U_hz_hr, axes=1)                                   # [batch, 2 * dim_decoder]\n","\t\tpre_z_r_vector = tf.sigmoid(emb_y_z_r_vector + \\\n","\t\thidden_z_r_vector)                                             # [batch, 2 * dim_decoder]\n","\n","\t\tr1 = pre_z_r_vector[:, :self.parser.hidden_dim]                # [batch, dim_decoder]\n","\t\tz1 = pre_z_r_vector[:, self.parser.hidden_dim:]                # [batch, dim_decoder]\n","\n","\t\temb_y_h_vector = tf.tensordot(emb, self.parser.W_yh, axes=1) + \\\n","\t\tself.parser.b_yh                                               # [batch, dim_decoder]\n","\t\thidden_r_h_vector = tf.tensordot(sample_h_pre,\n","\t\tself.parser.U_rh, axes=1)                                      # [batch, dim_decoder]\n","\t\thidden_r_h_vector *= r1\n","\t\tpre_h_proposal = tf.tanh(hidden_r_h_vector + emb_y_h_vector)\n","\n","\t\tpre_h = z1 * sample_h_pre + (1. - z1) * pre_h_proposal\n","\n","\t\tcontext, _, alpha_past = self.parser.attender.get_context(sample_annotation, pre_h, alpha_past_pre, None)  # [batch, dim_ctx]\n","\t\temb_y_z_r_nl_vector = tf.tensordot(pre_h, self.parser.U_hz_hr_nl, axes=1) + self.parser.b_hz_hr_nl\n","\t\tcontext_z_r_vector = tf.tensordot(context, self.parser.W_c_z_r, axes=1)\n","\t\tz_r_vector = tf.sigmoid(emb_y_z_r_nl_vector + context_z_r_vector)\n","\n","\t\tr2 = z_r_vector[:, :self.parser.hidden_dim]\n","\t\tz2 = z_r_vector[:, self.parser.hidden_dim:]\n","\n","\t\temb_y_h_nl_vector = tf.tensordot(pre_h, self.parser.U_rh_nl, axes=1) + self.parser.b_rh_nl\n","\t\temb_y_h_nl_vector *= r2\n","\t\tcontext_h_vector = tf.tensordot(context, self.parser.W_c_h_nl, axes=1)\n","\t\th_proposal = tf.tanh(emb_y_h_nl_vector + context_h_vector)\n","\t\th = z2 * pre_h + (1. - z2) * h_proposal\n","\n","\t\th_t = h\n","\t\tc_t = context\n","\t\talpha_past_t = alpha_past\n","\t\ty_t_1 = emb\n","\t\tlogit_gru = tf.tensordot(h_t, self.Wh, axes=1) + self.bh\n","\t\tlogit_ctx = tf.tensordot(c_t, self.Wc, axes=1) + self.bc\n","\t\tlogit_pre = tf.tensordot(y_t_1, self.Wy, axes=1) + self.by\n","\t\tlogit = logit_pre + logit_ctx + logit_gru   # batch x word_dim\n","\n","\t\t#### max pooling on vector with size equal to word_dim ####\n","\t\tshape = tf.shape(logit)\n","\t\tlogit = tf.reshape(logit, [-1, shape[1]//2, 2])\n","\t\tlogit = tf.reduce_max(logit, axis=2)\n","\n","\t\tlogit = tf.layers.dropout(inputs=logit, rate=0.2, training=self.training)\n","\n","\t\tlogit = tf.tensordot(logit, self.Wo, axes=1) + self.bo\n","\n","\t\tnext_probs = tf.nn.softmax(logits=logit)\n","\t\tnext_word  = tf.reduce_max(tf.multinomial(next_probs, num_samples=1), axis=1)\n","\t\treturn next_probs, next_word, h_t, alpha_past_t\n","\n","\t'''\n","\tCalculates sequence of labels/characters from annotations using beam search if stochastic is set to false \n","\t'''\n","\n","\tdef get_sample(self,p, w, h, alpha, ctx0, h_0, k , maxlen, stochastic, session, training):\n","\n","\t\tsample = []\n","\t\tsample_score = []\n","\n","\t\tlive_k = 1\n","\t\tdead_k = 0\n","\n","\t\thyp_samples = [[]] * 1\n","\t\thyp_scores = np.zeros(live_k).astype('float32')\n","\t\thyp_states = []\n","\n","\n","\t\tnext_alpha_past = np.zeros((ctx0.shape[0], ctx0.shape[1], ctx0.shape[2])).astype('float32')\n","\t\temb_0 = np.zeros((ctx0.shape[0], 256))\n","\n","\t\tnext_w = -1 * np.ones((1,)).astype('int64')\n","\n","\t\tnext_state = h_0\n","\t\tfor ii in range(maxlen):\n","\n","\t\t\tctx = np.tile(ctx0, [live_k, 1, 1, 1])\n","\n","\t\t\tinput_dict = {\n","\t\t\tanno:ctx,\n","\t\t\tinfer_y:next_w,\n","\t\t\talpha_past:next_alpha_past,\n","\t\t\th_pre:next_state,\n","\t\t\tif_trainning:training\n","\t\t\t}\n","      \n","\t\t\tnext_p, next_w, next_state, next_alpha_past = session.run([p, w, h, alpha], feed_dict=input_dict)\n","\t\t\tif stochastic:\n","\t\t\t\t\n","\t\t\t\tnw = next_w[0]\n","\t\t\t\tsample.append(nw)\n","\t\t\t\tsample_score += next_p[0, nw]\n","\t\t\t\tif nw == 0:\n","\t\t\t\t\tbreak\n","\t\t\telse:\n","\t\t\t\tcand_scores = hyp_scores[:, None] - np.log(next_p)\n","\t\t\t\tcand_flat = cand_scores.flatten()\n","\t\t\t\tranks_flat = cand_flat.argsort()[:(k-dead_k)]\n","\t\t\t\tvoc_size = next_p.shape[1]\n","\n","\t\t\t\tassert voc_size==NUM_CLASSES\n","\n","\t\t\t\ttrans_indices = ranks_flat // voc_size  # trans_indices are used to represent to different beams, values lies from k-dead_k\n","\t\t\t\tword_indices = ranks_flat % voc_size    # word_indices are used to represent to different label, values lies from 0-voc_size\n","\t\t\t\tcosts = cand_flat[ranks_flat]\n","\t\t\t\tnew_hyp_samples = []\n","\t\t\t\tnew_hyp_scores = np.zeros(k-dead_k).astype('float32')\n","\t\t\t\tnew_hyp_states = []\n","\t\t\t\tnew_hyp_alpha_past = []\n","\n","\t\t\t\tfor idx, [ti, wi] in enumerate(zip(trans_indices, word_indices)):\n","\t\t\t\t\tnew_hyp_samples.append(hyp_samples[ti]+[wi])    # concatenates [wi] list with list referring to beam ti \n","\t\t\t\t\tnew_hyp_scores[idx] = copy.copy(costs[idx])\n","\t\t\t\t\tnew_hyp_states.append(copy.copy(next_state[ti]))\n","\t\t\t\t\tnew_hyp_alpha_past.append(copy.copy(next_alpha_past[ti]))\n","\n","\t\t\t\tnew_live_k = 0\n","\t\t\t\thyp_samples = []\n","\t\t\t\thyp_scores = []\n","\t\t\t\thyp_states = []\n","\t\t\t\thyp_alpha_past = []\n","\n","\t\t\t\tfor idx in range(len(new_hyp_samples)):\n","\t\t\t\t\tif new_hyp_samples[idx][-1] == 0: # <eol>\n","\t\t\t\t\t\tsample.append(new_hyp_samples[idx])\n","\t\t\t\t\t\tsample_score.append(new_hyp_scores[idx])\n","\t\t\t\t\t\tdead_k += 1\n","\t\t\t\t\telse:\n","\t\t\t\t\t\tnew_live_k += 1\n","\t\t\t\t\t\thyp_samples.append(new_hyp_samples[idx])\n","\t\t\t\t\t\thyp_scores.append(new_hyp_scores[idx])\n","\t\t\t\t\t\thyp_states.append(new_hyp_states[idx])\n","\t\t\t\t\t\thyp_alpha_past.append(new_hyp_alpha_past[idx])\n","\t\t\t\thyp_scores = np.array(hyp_scores)\n","\t\t\t\tlive_k = new_live_k\n","\n","\t\t\t\tif new_live_k < 1:\n","\t\t\t\t\tbreak\n","\t\t\t\tif dead_k >= k:\n","\t\t\t\t\tbreak\n","\n","\t\t\t\tnext_w = np.array([w1[-1] for w1 in hyp_samples])\n","\t\t\t\tnext_state = np.array(hyp_states)\n","\t\t\t\tnext_alpha_past = np.array(hyp_alpha_past)\n","        \n","\n","\n","\t\tif not stochastic:\n","\t\t\t# dump every remaining one\n","\t\t\tif live_k > 0:\n","\t\t\t\tfor idx in range(live_k):\n","\t\t\t\t\tsample.append(hyp_samples[idx])\n","\t\t\t\t\tsample_score.append(hyp_scores[idx])\n","\n","\t\treturn sample, sample_score,next_alpha_past\n","\n","def cmp_result(label,rec):\n","    dist_mat = np.zeros((len(label)+1, len(rec)+1),dtype='int32')\n","    dist_mat[0,:] = range(len(rec) + 1)\n","    dist_mat[:,0] = range(len(label) + 1)\n","    for i in range(1, len(label) + 1):\n","        for j in range(1, len(rec) + 1):\n","            hit_score = dist_mat[i-1, j-1] + (label[i-1] != rec[j-1])\n","            ins_score = dist_mat[i,j-1] + 1\n","            del_score = dist_mat[i-1, j] + 1\n","            dist_mat[i,j] = min(hit_score, ins_score, del_score)\n","\n","    dist = dist_mat[len(label), len(rec)]\n","    return dist, len(label)\n","def convert(list): \n","      \n","    # Converting integer list to string list \n","    s = [str(i) for i in list] \n","      \n","    # Join list items using join() \n","    res = \"\".join(s)\n","      \n","    return(res) \n","def process_chr_error(recfile, labelfile, resultfile):\n","    total_dist = 0\n","    total_label = 0\n","    total_line = 0\n","    total_line_rec = 0\n","    rec_mat = {}\n","    label_mat = {}\n","    cc=1\n","    with open(recfile) as f_rec:\n","        for line in f_rec:\n","            tmp = line.split()\n","            key = tmp[0]\n","            latex = tmp[1:]\n","            rec_mat[key] = latex\n","            cc=cc+1\n","    cc=1\n","    with open(labelfile) as f_label:\n","        for line in f_label:\n","            tmp = line.split()\n","            key = tmp[0]\n","            latex = tmp[1:]\n","            label_mat[key] = latex\n","            cc=cc+1\n","    for key_rec in rec_mat:\n","        label = label_mat[key_rec]\n","        rec = rec_mat[key_rec]\n","        dist, llen = cmp_result(label, rec)\n","        total_dist += dist\n","        total_label += llen\n","        total_line += 1\n","        if dist == 0:\n","            total_line_rec += 1\n","    chr_error = float(total_dist)/total_label\n","    line_rec = float(total_line_rec)/total_line\n","    return chr_error, line_rec\n","def process_wer_error(recfile, labelfile, resultfile):\n","    total_dist = 0\n","    total_label = 0\n","    total_line = 0\n","    total_line_rec = 0\n","    rec_mat = {}\n","    label_mat = {}\n","    cc=1\n","    with open(recfile) as f_rec:\n","        for line in f_rec:\n","            tmp = line.split()\n","            key = tmp[0]\n","            latex = tmp[1:]\n","            ss=convert(latex)\n","            latex = ss.split(\"4\")\n","            rec_mat[key] = latex\n","            cc=cc+1\n","    cc=1\n","    with open(labelfile) as f_label:\n","        for line in f_label:\n","            tmp = line.split()\n","            key = tmp[0]\n","            latex = tmp[1:]\n","            ss=convert(latex)\n","            latex = ss.split(\"4\")\n","            label_mat[key] = latex\n","            cc=cc+1\n","    for key_rec in rec_mat:\n","        label = label_mat[key_rec]\n","        rec = rec_mat[key_rec]\n","        dist, llen = cmp_result(label, rec)\n","        total_dist += dist\n","        total_label += llen\n","       \n","    wer = float(total_dist)/total_label\n","    return wer\n","def process(recfile, labelfile, resultfile):\n","\t\t[cer,ler]=process_chr_error(recfile, labelfile, resultfile)\n","\t\twer=process_wer_error(recfile, labelfile, resultfile)\n","\t\tf_result = open(resultfile,'w')\n","\t\tf_result.write('CER {}\\n'.format(cer))\n","\t\tf_result.write('WER {}\\n'.format(wer))\n","\t\tf_result.write('LER {}\\n'.format(ler))\n","\t\tf_result.close()\n","\n","def dataIterator(feature_file,label_file,batch_size,batch_Imagesize,maxlen,maxImagesize):\n","    \n","    fp=open(feature_file,'rb')\n","    features=pkl.load(fp)\n","    fp.close()\n","\n","    fp2=open(label_file,'rb')\n","    labels=pkl.load(fp2)\n","    fp2.close()\n","    \n","\n","    imageSize={}\n","    for uid,fea in features.items():\n","        \n","        imageSize[uid]=fea.shape[0]*fea.shape[1]\n","\n","    imageSize= sorted(imageSize.items(), key=lambda d:d[1]) # sorted by sentence length,  return a list with each triple element\n","\n","    feature_batch=[]\n","    label_batch=[]\n","    feature_total=[]\n","    label_total=[]\n","    uidList=[]\n","\n","    batch_image_size=0\n","    biggest_image_size=0\n","    i=0\n","    for uid,size in imageSize:\n","        if size>biggest_image_size:\n","            biggest_image_size=size\n","        fea=features[uid]\n","        lab=labels[uid]\n","        batch_image_size=biggest_image_size*(i+1)\n","        if len(lab)>maxlen:\n","            print('sentence', uid, 'length bigger than', maxlen, 'ignore')\n","        elif size>maxImagesize:\n","            print('image', uid, 'size bigger than', maxImagesize, 'ignore')\n","        else:\n","            uidList.append(uid)\n","            if batch_image_size>batch_Imagesize or i==batch_size: # a batch is full\n","                feature_total.append(feature_batch)\n","                label_total.append(label_batch)\n","\n","                i=0\n","                biggest_image_size=size\n","                feature_batch=[]\n","                label_batch=[]\n","                feature_batch.append(fea)\n","                label_batch.append(lab)\n","                batch_image_size=biggest_image_size*(i+1)\n","                i+=1\n","            else:\n","                feature_batch.append(fea)\n","                label_batch.append(lab)\n","                i+=1\n","\n","    # last batch\n","    feature_total.append(feature_batch)\n","    label_total.append(label_batch)\n","\n","    print('total ',len(feature_total), 'batch data loaded')\n","\n","    return list(zip(feature_total,label_total)),uidList\n","\n","def prepare_data(images_x, seqs_y, n_words_src=30000,\n","                 n_words=30000):\n","\n","    heights_x = [s.shape[0] for s in images_x]\n","    widths_x = [s.shape[1] for s in images_x]\n","    lengths_y = [len(s) for s in seqs_y]\n","\n","    n_samples = len(heights_x)\n","    max_height_x = np.max(heights_x)\n","    max_width_x = np.max(widths_x)\n","    maxlen_y = np.max(lengths_y) + 1\n","    x = np.zeros((n_samples, max_height_x, max_width_x)).astype('float32')\n","    \n","    y =np.zeros((maxlen_y, n_samples)).astype('int64') # the <eol> must be 0 in the dict !!!\n","    x_mask =np.zeros((n_samples, max_height_x, max_width_x)).astype('float32')\n","    y_mask = np.zeros((maxlen_y, n_samples)).astype('float32')\n"," \n","    for idx, [s_x, s_y] in enumerate(zip(images_x, seqs_y)):\n","\n","        #s_x=(s_x / 255.) # [B, C, H, W] -> [B, H, W, C]       \n","        if len(s_x.shape)>2:\n","          s_x= cv2.cvtColor(s_x.astype('float32'), cv2.COLOR_BGR2GRAY)\n","        x[idx, :heights_x[idx], :widths_x[idx]] = s_x/255.\n","        x_mask[idx, :heights_x[idx], :widths_x[idx]] = 1.\n","        y[:lengths_y[idx], idx] = s_y\n","        y_mask[:lengths_y[idx], idx] = 1.\n","    return x, x_mask, y, y_mask\n","\n","def main():\n","\t#### encoder setup parameters ####\n","  dense_blocks=3\n","  levels_count=16\n","  growth=24\n","  #### decoder setup parameters ####\n","  hidden_dim=256\n","  word_dim=256\n","  dim_attend=512\n","\n","  #### Loding Data ####\n","  train,train_uid_list = dataIterator('/gdrive/My Drive/URDU_V2_Exp/wap_exp/data/trainImages_v2.pkl','/gdrive/My Drive/URDU_V2_Exp/wap_exp/data/trainLabels_v2.pkl', batch_size=BATCHSIZE, batch_Imagesize=500000,maxlen=130, maxImagesize=500000)\n","  valid, valid_uid_list = dataIterator('/gdrive/My Drive/URDU_V2_Exp/wap_exp/testdata/validImages_v2.pkl','/gdrive/My Drive/URDU_V2_Exp/wap_exp/testdata/validLabels_v2.pkl',batch_size=BATCHSIZE, batch_Imagesize=500000,maxlen=130, maxImagesize=500000)\n","  test, test_uid_list = dataIterator('/gdrive/My Drive/URDU_V2_Exp/wap_exp/testdata/testImages_v2.pkl','/gdrive/My Drive/URDU_V2_Exp/wap_exp/testdata/testLabels_v2.pkl',batch_size=1, batch_Imagesize=500000,maxlen=130, maxImagesize=500000)\n","\n","  #### Graph Creation ####\n","  with tf.Graph().as_default():\n","\t\n","    x = tf.placeholder(tf.float32, shape=[None, None, None])\t\n","    y = tf.placeholder(tf.int32, shape=[None, None])\t\n","   \n","    x_mask = tf.placeholder(tf.float32, shape=[None, None, None])\t\n","    y_mask = tf.placeholder(tf.float32, shape=[None, None])\n","\t\n","    lr = tf.placeholder(tf.float32, shape=())\n","\n","    global anno, infer_y, h_pre, alpha_past, if_trainning\n","\t\t\n","    if_trainning = tf.placeholder(tf.bool, shape=())\n","    alpha_reg = tf.placeholder(tf.float32, shape=())\n","\n","    watcher_train = Watcher_train(blocks=dense_blocks,level=levels_count, growth_rate=growth, training=if_trainning)\t\n","    annotation, anno_mask = watcher_train.dense_net(x, x_mask)\n","\n","    # for initilaizing validation\n","    anno = tf.placeholder(tf.float32, shape=[None, annotation.shape.as_list()[1], annotation.shape.as_list()[2], annotation.shape.as_list()[3]])\n","    infer_y = tf.placeholder(tf.int64, shape=(None,))\n","    h_pre = tf.placeholder(tf.float32, shape=[None, hidden_dim])\n","    alpha_past = tf.placeholder(tf.float32, shape=[None, annotation.shape.as_list()[1], annotation.shape.as_list()[2]])\n","\t\n","    attender = Attender(annotation.shape.as_list()[3], hidden_dim, dim_attend)\t\n","    parser = Parser(hidden_dim, word_dim, attender, annotation.shape.as_list()[3])\t\n","    wap = WAP(watcher_train, attender, parser,hidden_dim,word_dim, annotation.shape.as_list()[3], num_classes, if_trainning)\n","\t\n","    hidden_state_0 = tf.tanh(tf.tensordot(tf.reduce_mean(anno, axis=[1, 2]), wap.Wa2h, axes=1) + wap.ba2h)  # [batch, hidden_dim]\n","\t  \n","    cost = wap.get_cost(annotation, y, anno_mask, y_mask, alpha_reg)\n","    \n","\t\t#### regularization of densenet variables ####\n","    #alpha_c=0.5\n","    vs = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n","    for vv in vs:\n","    \tif not vv.name.startswith('conv2d'):\n","    \t\tcost += 1e-4 * tf.reduce_sum(tf.pow(vv, 2))\n","\t\t\t  \n","\n","    p, w, h, alpha = wap.get_word(infer_y, h_pre, alpha_past, anno)\n","    optimizer = tf.train.AdadeltaOptimizer(learning_rate=lr)\n","\n","\t\t#### gradients clipping ####\n","    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","    with tf.control_dependencies(update_ops):\t\t\t\n","    \ttvars= tf.trainable_variables()\n","    \tgrads, _  = tf.clip_by_global_norm(tf.gradients(cost, tvars),100)\n","    \ttrainer = optimizer.apply_gradients(zip(grads, tvars))\n","    \t\n","      \n","\t\t\t\n","    \n","    uidx = 0\n","    cost_s = 0\n","    cost_i=0\n","    dispFreq = 200\n","    saveFreq = len(train)\n","    sampleFreq = len(train)\n","    validFreq = len(train)\n","    history_errs = []\n","    estop = False\n","    halfLrFlag = 0\n","    patience = 15\n","    lrate = 1\n","    log = open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/log.txt', 'w')\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth=True\n","    init = tf.global_variables_initializer()\n","    \n","    saver = tf.train.Saver(max_to_keep=None)\n","    checkpoint_path = '/gdrive/My Drive/URDU_V2_Exp/wap_exp/model2/cp-{ckpt:04d}-{acc:04f}.ckpt'\n","\n","    with tf.Session(config=config) as sess:\n","    \tsess.run(init)\n","    \tsaver.restore(sess, '/gdrive/My Drive/URDU_V2_Exp/wap_exp/model2/cp-0045-25.278371.ckpt')#tf.train.latest_checkpoint('/gdrive/My Drive/urdu final v2/model2/'))cp-0045-25.278371.ckpt\n","    \t###Testing mode ###\t\n","    \tif(MODE=='train'):\n","    \t\tfor epoch in range(1,50):\n","    \t\t\tn_samples = 0\n","    \t\t\trandom.shuffle(train)\n","    \t\t\tstart_time = time.time()\n","    \n","    \t\t\tfor batch_x, batch_y in train:\n","    \t\t\t\tbatch_x, batch_x_m, batch_y, batch_y_m = prepare_data(batch_x, batch_y,BATCHSIZE)         \n","    \t\t\t\tuidx += 1\n","    \t\t\t\tcost_i, _ = sess.run([cost,trainer],feed_dict={x:batch_x, y:batch_y, x_mask:batch_x_m, y_mask:batch_y_m, if_trainning:True, lr:lrate, alpha_reg:1})\n","    \t\t\t\tcost_s +=cost_i\n","    \t\t\t\tif np.isnan(cost_i) or np.isinf(cost_i):\n","    \t\t\t\t\tprint('invalid cost value detected')\n","    \t\t\t\t\tsys.exit(0)\n","    \t\t\t\tif np.mod(uidx, dispFreq) == 0:\n","    \t\t\t\t\tcost_s /= dispFreq\n","    \t\t\t\t\tprint('Epoch ', epoch, 'Update ', uidx, 'Cost ', cost_s, 'Lr ', lrate)\n","    \t\t\t\t\tlog.write('Epoch ' + str(epoch) + ' Update ' + str(uidx) + ' Cost ' + str(cost_s) + ' Lr ' + str(lrate) + '\\n')\n","    \t\t\t\t\tlog.flush()\n","    \t\t\t\t\tcost_s = 0\n","    \t\t\t\tif np.mod(uidx,sampleFreq) == 0:\n","    \t\t\t\t\tfpp_sample = open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/valid_predicted.txt', 'w')\n","    \t\t\t\t\tfpp_sample2=open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/valid_target.txt', 'w')\n","    \t\t\t\t\tvalid_count_idx = 0  \n","    \t\t\t\t\tfor batch_x, batch_y in valid:\n","    \t\t\t\t\t\tfor idxx,[xx,yy] in enumerate(zip(batch_x,batch_y)): \n","    \t\t\t\t\t\t\tif len(xx.shape)>2:\n","    \t\t\t\t\t\t\t\txx= cv2.cvtColor(xx.astype('float32'), cv2.COLOR_BGR2GRAY)\n","    \t\t\t\t\t\t\txx_pad = np.zeros((xx.shape[0], xx.shape[1]), dtype='float32')\n","    \t\t\t\t\t\t\txx_pad[:xx.shape[0],:xx.shape[1]] =xx/255.\n","    \t\t\t\t\t\t\txx_pad = xx_pad[None, :, :]\n","    \t\t\t\t\t\t\tannot = sess.run(annotation, feed_dict={x:xx_pad, if_trainning:False})\n","    \t\t\t\t\t\t\th_state = sess.run(hidden_state_0, feed_dict={anno:annot})\n","    \t\t\t\t\t\t\tsample, score,hypalpha = wap.get_sample( p, w, h, alpha,annot, h_state,10, 130, False, sess, training=False)\n","    \t\t\t\t\t\t\tscore = score / np.array([len(s) for s in sample])\n","    \t\t\t\t\t\t\tss = sample[score.argmin()]\n","    \t\t\t\t\t\t\tfpp_sample.write(str(valid_uid_list[valid_count_idx])+'im')\n","    \t\t\t\t\t\t\tfpp_sample2.write(str(valid_uid_list[valid_count_idx])+'im')\n","    \t\t\t\t\t\t\tvalid_count_idx=valid_count_idx+1\n","    \t\t\t\t\t\t\tif np.mod(valid_count_idx, 200) == 0:\n","    \t\t\t\t\t\t\t\tprint('gen %d samples'%valid_count_idx)\n","    \t\t\t\t\t\t\t\tlog.write('gen %d samples'%valid_count_idx + '\\n')\n","    \t\t\t\t\t\t\t\tlog.flush()\n","    \t\t\t\t\t\t\tfor vv in ss:\n","    \t\t\t\t\t\t\t\tif vv == 0: # <eol>\n","    \t\t\t\t\t\t\t\t\tbreak\n","    \t\t\t\t\t\t\t\tfpp_sample.write(' '+str(vv))\n","    \t\t\t\t\t\t\tfor y1 in yy:\n","    \t\t\t\t\t\t\t\tfpp_sample2.write(' '+str(y1))\n","    \t\t\t\t\t\t\tfpp_sample.write('\\n')\n","    \t\t\t\t\t\t\tfpp_sample2.write('\\n')\n","    \t\t\t\t\tfpp_sample.close()\n","    \t\t\t\t\tfpp_sample2.close()\n","    \t\t\t\t\tprint('valid set decode done')\n","    \t\t\t\t\tlog.write('valid set decode done\\n')\n","    \t\t\t\t\tlog.flush()\n","    \t\t\t\tif np.mod(uidx, validFreq) == 0:\n","    \t\t\t\t\tprobs = []\n","    \t\t\t\t\tfor batch_x, batch_y in valid:\n","    \t\t\t\t\t\tbatch_x, batch_x_m, batch_y, batch_y_m = prepare_data(batch_x, batch_y,BATCHSIZE)\n","    \t\t\t\t\t\tpprobs, annott = sess.run([cost, annotation], feed_dict={x:batch_x, y:batch_y, x_mask:batch_x_m, y_mask:batch_y_m, if_trainning:False, alpha_reg:1})\n","    \t\t\t\t\t\tprobs.append(pprobs)\n","    \t\t\t\t\tvalid_errs = np.array(probs)\n","    \t\t\t\t\tvalid_err_cost = valid_errs.mean()\n","    \t\t\t\t\tprocess( '/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/valid_predicted.txt', '/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/valid_target.txt' , '/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/valid-wer.wer')\n","    \t\t\t\t\tfpp=open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/valid-wer.wer')\n","    \t\t\t\t\tstuff=fpp.readlines()\n","    \t\t\t\t\tfpp.close()\n","    \t\t\t\t\tm=re.search('CER (.*)\\n',stuff[0])\n","    \t\t\t\t\tvalid_cer=100. * float(m.group(1))\n","    \t\t\t\t\tm=re.search('WER (.*)\\n',stuff[1])\n","    \t\t\t\t\tvalid_wer=100. * float(m.group(1))\n","    \t\t\t\t\tm=re.search('LER (.*)\\n',stuff[2])\n","    \t\t\t\t\tvalid_ler=100. * float(m.group(1))\n","    \t\t\t\t\tvalid_err=valid_cer\n","    \t\t\t\t\thistory_errs.append(valid_err)\n","    \t\t\t\t\tif uidx/validFreq == 0 or valid_err <= np.array(history_errs).min():\n","    \t\t\t\t\t\tbad_counter = 0\n","    \t\t\t\t\tif uidx/validFreq != 0 and valid_err > np.array(history_errs).min():\n","    \t\t\t\t\t\tbad_counter += 1\n","    \t\t\t\t\t\tif bad_counter > patience:\n","    \t\t\t\t\t\t\tif halfLrFlag==2:\n","    \t\t\t\t\t\t\t\tprint('Early Stop!')\n","    \t\t\t\t\t\t\t\tlog.write('Early Stop!\\n')\n","    \t\t\t\t\t\t\t\tlog.flush()\n","    \t\t\t\t\t\t\t\testop = True\n","    \t\t\t\t\t\t\t\tbreak\n","    \t\t\t\t\t\t\telse:\n","    \t\t\t\t\t\t\t\tprint('Lr decay and retrain!')\n","    \t\t\t\t\t\t\t\tlog.write('Lr decay and retrain!\\n')\n","    \t\t\t\t\t\t\t\tlog.flush()\n","    \t\t\t\t\t\t\t\tbad_counter = 0\n","    \t\t\t\t\t\t\t\tlrate = lrate / 10\n","    \t\t\t\t\t\t\t\thalfLrFlag += 1\n","\t\n","    \t\t\t\t\tprint('Valid CER: %.2f%%,Valid WER: %.2f%%, ExpRate: %.2f%%, Cost: %f' % (valid_cer,valid_wer,valid_ler,valid_err_cost))\n","    \t\t\t\t\tlog.write('Valid CER: %.2f%%,Valid WER: %.2f%%, ExpRate: %.2f%%, Cost: %f' % (valid_cer,valid_wer,valid_ler,valid_err_cost) + '\\n')\n","    \t\t\t\t\tlog.flush()\n","\t\n","    \t\t\t\t\tduration = time.time() - start_time\n","    \t\t\t\t\tprint('1 itr completion time: %.2f%%' %(duration)+'\\n')\n","    \t\t\t\t\t#save_path = saver.save(sess, checkpoint_path.format(ckpt=epoch,acc=valid_cer))\n","    \t\t\tif estop:\n","    \t\t\t\tbreak\n","    \t###Testing mode ###\t\t\t\n","    \tif(MODE=='test'):\n","    \t\tfpp_sample = open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/test_predicted.txt', 'w')\n","    \t\tfpp_sample2=open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/test_target.txt', 'w')\n","\n","    \t\ttest_count_idx = 0  \n","    \t\tfor batch_x, batch_y in test:\n","    \t\t\tfor idxx,[xx,yy] in enumerate(zip(batch_x,batch_y)): \n","    \t\t\t\tif len(xx.shape)>2:\n","    \t\t\t\t\txx= cv2.cvtColor(xx.astype('float32'), cv2.COLOR_BGR2GRAY)\n","    \t\t\t\txx_pad = np.zeros((xx.shape[0], xx.shape[1]), dtype='float32')\n","    \t\t\t\txx_pad[:xx.shape[0],:xx.shape[1]] =xx/255.\n","    \t\t\t\txx_pad = xx_pad[None, :, :]\n","    \t\t\t\tannot = sess.run(annotation, feed_dict={x:xx_pad, if_trainning:False})\n","    \t\t\t\th_state = sess.run(hidden_state_0, feed_dict={anno:annot})\n","    \t\t\t\tsample, score,hypalpha = wap.get_sample( p, w, h, alpha,annot, h_state,10, 130, False, sess, training=False)\n","    \t\t\t\tscore = score / np.array([len(s) for s in sample])\n","    \t\t\t\tss = sample[score.argmin()]\n","    \t\t\t\t\t\n","    \t\t\t\tfpp_sample.write(str(valid_uid_list[test_count_idx])+'im')\n","    \t\t\t\tfpp_sample2.write(str(valid_uid_list[test_count_idx])+'im')\n","    \t\t\t\ttest_count_idx=test_count_idx+1\n","    \t\t\t\tif np.mod(test_count_idx, 200) == 0:\n","    \t\t\t\t\tprint('gen %d samples'%test_count_idx)\n","    \t\t\t\t\tlog.write('gen %d samples'%test_count_idx + '\\n')\n","    \t\t\t\t\tlog.flush()\n","    \t\t\t\tfor vv in ss:\n","    \t\t\t\t\tif vv == 0: # <eol>\n","    \t\t\t\t\t\tbreak\n","    \t\t\t\t\tfpp_sample.write(' '+str(vv))\n","    \t\t\t\tfor y1 in yy:\n","    \t\t\t\t\tfpp_sample2.write(' '+str(y1))\n","    \t\t\t\tfpp_sample.write('\\n')\n","    \t\t\t\tfpp_sample2.write('\\n')\n","    \t\tfpp_sample.close()\n","    \t\tfpp_sample2.close()\n","    \t\tprint('test set decode done')\n","    \t\tlog.write('test set decode done\\n')\n","    \t\tlog.flush()\t\t\n","    \t\tprocess( '/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/test_predicted.txt', '/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/test_target.txt' , '/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/test-wer.wer')\n","    \t\tfpp=open('/gdrive/My Drive/URDU_V2_Exp/wap_exp/result/test-wer.wer')\n","    \t\tstuff=fpp.readlines()\n","    \t\tfpp.close()\n","    \t\tm=re.search('CER (.*)\\n',stuff[0])\n","    \t\ttest_cer=100. * float(m.group(1))\n","    \t\tm=re.search('WER (.*)\\n',stuff[1])\n","    \t\ttest_wer=100. * float(m.group(1))\n","    \t\tm=re.search('LER (.*)\\n',stuff[2])\n","    \t\ttest_ler=100. * float(m.group(1)) \t\t\t\n","    \t\tprint('test CER: %.2f%%,test WER: %.2f%%, ExpRate: %.2f%%' % (test_cer,valid_wer,test_ler))\n","    \t\tlog.write('test CER: %.2f%%,test WER: %.2f%%, ExpRate: %.2f%%' % (test_cer,valid_wer,test_ler) + '\\n')\n","    \t\tlog.flush()\t\t \n","\t\t\t\n","if __name__ == \"__main__\":\n","\tmain()\n"],"execution_count":null,"outputs":[]}]}